# thesisliterature
This repo contains all literature used for the background section in the thesis paper to be published. This readme will include an annotated list of each read paper. 

## Papers
### Robustness of decentralised learning to nodes and data disruption. 
In my opinion this paper is usefull to refer in the related work section. This paper talks about an extended version of federated learning, fully decentralized learning. This type of learning eliminates the need of a central parameter server that collects and aggregates model parameters. Altough this paper does not the same as what I do in the thesis project (decentralized learning with a parameter server) this is still relevant to relate to to show what other papers are working on.

### Decentralised Learning in Federated Deployment Environments: A System-Level Survey.
This a very relevant paper for taxonomy. I can use it to better back up my baseline configuration of PyTorch, TensorFlow, and the SAM implementation. Furthermore it discusses the concern of privacy instead of fault tolerance. This is an aspect that I dont discuss in the thesis paper, so this might be relevant to refer to in the related works or background section.

### DART : A Solution for decentralized federated learning model robustness analysis
This paper focusses mainly on the different kinds of poisoning attacks on Centralized and Decentralized Federated Learning systems. The paper discusses the different ways of attacks but also the different ways of defending mechanisms. It then further comes up with a system called DART to analyse the robustness of an FL system against poisoning attacks. I think this paper is good for both the background and related works section, because it discusses core concepts of FL and discusses poisoning attacks (a different form of disruption than node failures.) Now This paper led me to think that building robust systems for FL against node failures is only important when the majority of federated entities is owned by a single share holder. If one company runs a federated learning system inhouse then node failures are important to defend against. If multiple companies share their learning it might not be important if a single company in this federated system fails if and only if this company can learn by itself.

### Analyzing the robustness of decentralized horizontal and vertical federated learning architectures in a non-IID scenario
Just like the paper about DART, this paper focusses on adverserial attacks in federated environments. The paper discusses the same forms of poisoning attacks. A different thing this paper does is look at federated learning in a horizontal and vertical way. I have not seen this in any other paper yet. Horizontal FL is when all entities share the same feature space but have different samples. Vertical FL is when all entities share the same samples but a different feature space. I don't really know how relevant all this information is for my paper. Furthermore they discuss all these systems in a non-IID scenario, which they do the resemble a scenario that comes closes to a real world scenario. 

## Tech Blogs
### Fault Tolerant Llama: training with 2000 synthetic failures every ~15 seconds and no checkpoints on Crusoe L40S 
(https://pytorch.org/blog/fault-tolerant-llama-training-with-2000-synthetic-failures-every-15-seconds-and-no-checkpoints-on-crusoe-l40s/)
I think one common aspect the pot and my paper share is the fact that fault tolerance using checkpointing creates a bottleneck for pytorch distributed training. Both the blogpost and my thesis paper address this and come-up with a different way of handling fault tolerance without using checkpointing. Both ways of FT are different, I don't use heartbeats for instance, I fall back on the properties of the SAM. A key difference is the realism in which runs/trials are done. The blogpost is more realistic than my tiny toy example on a single cpu. Although it is a good proof of concept that we could scale up eventually. (maybe for making a comparison or just a topic to discuss in the background section.)
